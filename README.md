# RL-CourseProject

## DQN
Reading and coding up the DQN paper to solve any of the discrete-space, classic control environments by OpenAI gym, here CartPole-v0 is used.

Report on plots on performances, observations and inferences on hyperparameter
variation. <br/> 
Analysis of performance and inferences drawn on removal of the target network and the transition replay buffer (as proposed by the original DQN paper for smooth and stable learning of the neural nets) <br/><br/>
*Reference*: https://arxiv.org/pdf/1312.5602
